from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
import faiss
import pickle
import numpy as np
import os
import google.generativeai as genai
import time

app = FastAPI()

# 1. C·∫•u h√¨nh CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], 
    allow_methods=["*"],
    allow_headers=["*"],
)

# 2. Qu·∫£n l√Ω API Keys
GOOGLE_KEYS_STR = os.getenv("GOOGLE_API_KEYS", "")
GOOGLE_KEYS = [k.strip() for k in GOOGLE_KEYS_STR.split(",") if k.strip()]
key_index = 0

def get_current_key():
    global key_index
    if not GOOGLE_KEYS: return None
    return GOOGLE_KEYS[key_index % len(GOOGLE_KEYS)]

# 3. Load Database Vector (Ch·ªâ load 1 l·∫ßn khi kh·ªüi ƒë·ªông)
print("üì• ƒêang t·∫£i c∆° s·ªü d·ªØ li·ªáu lu·∫≠t (Local)...")
index = None
documents = None

try:
    if os.path.exists("luat_vn.index") and os.path.exists("luat_vn.pkl"):
        index = faiss.read_index("luat_vn.index")
        with open("luat_vn.pkl", "rb") as f:
            documents = pickle.load(f)
        print(f"‚úÖ ƒê√£ t·∫£i xong! T·ªïng c·ªông {len(documents)} ƒëo·∫°n lu·∫≠t.")
    else:
        print("‚ö†Ô∏è L·ªói: Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu. H√£y ch·∫°y build_db.py tr∆∞·ªõc!")
except Exception as e:
    print(f"‚ùå L·ªói khi t·∫£i DB: {e}")

# 4. H√†m ch·ªâ t√¨m ki·∫øm Vector (B·ªè Online)
def vector_search_only(query):
    if not index or not documents:
        return "H·ªá th·ªëng ch∆∞a c√≥ d·ªØ li·ªáu lu·∫≠t. Vui l√≤ng li√™n h·ªá qu·∫£n tr·ªã vi√™n n·∫°p d·ªØ li·ªáu."

    try:
        genai.configure(api_key=get_current_key())
        
        # M√£ h√≥a c√¢u h·ªèi th√†nh Vector
        res = genai.embed_content(
            model="models/text-embedding-004",
            content=query,
            task_type="retrieval_query"
        )
        q_vec = np.array([res['embedding']]).astype('float32')
        faiss.normalize_L2(q_vec) # Chu·∫©n h√≥a ƒë·ªÉ t√≠nh Cosine Similarity
        
        # T√¨m 5 ƒëo·∫°n lu·∫≠t kh·ªõp nh·∫•t
        scores, indices = index.search(q_vec, 5)
        
        # L·ªçc k·∫øt qu·∫£: Ch·ªâ l·∫•y nh·ªØng ƒëo·∫°n c√≥ ƒë·ªô t∆∞∆°ng ƒë·ªìng > 0.35
        # (N·∫øu th·∫•p qu√° nghƒ©a l√† kh√¥ng li√™n quan -> B·ªè qua)
        relevant_docs = []
        for i, score in enumerate(scores[0]):
            if score >= 0.35: 
                relevant_docs.append(documents[indices[0][i]])
        
        if relevant_docs:
            return "\n---\n".join(relevant_docs)
        else:
            return "" # Kh√¥ng t√¨m th·∫•y g√¨ li√™n quan
            
    except Exception as e:
        print(f"L·ªói t√¨m ki·∫øm Vector: {e}")
        return ""

# 5. API X·ª≠ l√Ω
class ChatRequest(BaseModel):
    prompt: str

@app.post("/api/process")
async def process_data(request: ChatRequest):
    user_input = request.prompt
    
    # B∆∞·ªõc 1: T√¨m trong Vector DB
    context = vector_search_only(user_input)
    
    # B∆∞·ªõc 2: X·ª≠ l√Ω Prompt cho AI
    if context:
        # Tr∆∞·ªùng h·ª£p t√¨m th·∫•y lu·∫≠t
        system_prompt = f"""
        B·∫°n l√† Tr·ª£ l√Ω Ph√°p lu·∫≠t Giao th√¥ng Vi·ªát Nam (Ngh·ªã ƒë·ªãnh 168/2024).
        D∆∞·ªõi ƒë√¢y l√† th√¥ng tin tr√≠ch xu·∫•t t·ª´ vƒÉn b·∫£n lu·∫≠t ch√≠nh x√°c:
        ---------------------
        {context}
        ---------------------
        Y√äU C·∫¶U:
        1. CH·ªà s·ª≠ d·ª•ng th√¥ng tin ƒë∆∞·ª£c cung c·∫•p ·ªü tr√™n ƒë·ªÉ tr·∫£ l·ªùi.
        2. N·∫øu th√¥ng tin c√≥ ƒë·ªÅ c·∫≠p m·ª©c ph·∫°t ti·ªÅn, h√£y ghi r√µ con s·ªë c·ª• th·ªÉ.
        3. Tr·∫£ l·ªùi ng·∫Øn g·ªçn, ƒëi th·∫≥ng v√†o v·∫•n ƒë·ªÅ.
        """
        final_prompt = f"Ng∆∞·ªùi d√πng h·ªèi: {user_input}"
    else:
        # Tr∆∞·ªùng h·ª£p KH√îNG t√¨m th·∫•y trong Vector (H·ªèi ngo√†i l·ªÅ ho·∫∑c d·ªØ li·ªáu thi·∫øu)
        system_prompt = """
        B·∫°n l√† Tr·ª£ l√Ω Giao th√¥ng.
        Ng∆∞·ªùi d√πng ƒëang h·ªèi m·ªôt c√¢u m√† h·ªá th·ªëng d·ªØ li·ªáu lu·∫≠t hi·ªán t·∫°i KH√îNG t√¨m th·∫•y th√¥ng tin kh·ªõp.
        H√£y tr·∫£ l·ªùi kh√©o l√©o r·∫±ng: "Xin l·ªói, hi·ªán t·∫°i trong c∆° s·ªü d·ªØ li·ªáu c·ªßa t√¥i ch∆∞a c√≥ th√¥ng tin c·ª• th·ªÉ v·ªÅ v·∫•n ƒë·ªÅ n√†y. B·∫°n c√≥ th·ªÉ h·ªèi r√µ h∆°n v·ªÅ c√°c l·ªói vi ph·∫°m ph·ªï bi·∫øn kh√¥ng?"
        """
        final_prompt = f"C√¢u h·ªèi: {user_input}"

    # B∆∞·ªõc 3: G·ªçi Gemini tr·∫£ l·ªùi
    global key_index
    for _ in range(len(GOOGLE_KEYS)):
        try:
            genai.configure(api_key=get_current_key())
            model = genai.GenerativeModel('gemini-2.5-flash')
            response = model.generate_content(
                f"{system_prompt}\n\n{final_prompt}"
            )
            return {"answer": response.text}
        except:
            key_index += 1
            time.sleep(0.5)
            
    return {"answer": "H·ªá th·ªëng ƒëang b·∫≠n, vui l√≤ng th·ª≠ l·∫°i sau gi√¢y l√°t."}
