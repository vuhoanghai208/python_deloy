from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
import faiss
import pickle
import numpy as np
import os
import google.generativeai as genai
from openai import OpenAI
import time

app = FastAPI()

# 1. Cáº¥u hÃ¬nh CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], 
    allow_methods=["*"],
    allow_headers=["*"],
)

# 2. Cáº¤U HÃŒNH API KEYS
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
openai_client = OpenAI(api_key=OPENAI_API_KEY)

GOOGLE_KEYS_STR = os.getenv("GOOGLE_API_KEYS", "")
GOOGLE_KEYS = [k.strip() for k in GOOGLE_KEYS_STR.split(",") if k.strip()]
key_index = 0

def get_current_google_key():
    global key_index
    if not GOOGLE_KEYS: return None
    return GOOGLE_KEYS[key_index % len(GOOGLE_KEYS)]

# 3. Health Check
@app.get("/")
def read_root():
    return {"status": "Hybrid Server (Law + Social) is running"}

# 4. HÃ€M LOAD DATABASE (Chung cho cáº£ Luáº­t vÃ  XÃ£ giao)
def load_db(name_index, name_pkl):
    print(f"ğŸ“¥ Äang táº£i DB: {name_index}...")
    if os.path.exists(name_index) and os.path.exists(name_pkl):
        try:
            idx = faiss.read_index(name_index)
            with open(name_pkl, "rb") as f:
                docs = pickle.load(f)
            print(f"âœ… ÄÃ£ táº£i xong {name_index}: {len(docs)} Ä‘oáº¡n.")
            return idx, docs
        except Exception as e:
            print(f"âŒ Lá»—i táº£i {name_index}: {e}")
            return None, None
    else:
        print(f"âš ï¸ KhÃ´ng tÃ¬m tháº¥y file {name_index} (Bá» qua).")
        return None, None

# --- LOAD Cáº¢ 2 DB ---
index_luat, docs_luat = load_db("luat_vn.index", "luat_vn.pkl")
index_social, docs_social = load_db("xa_giao.index", "xa_giao.pkl")

# 5. HÃ€M TÃŒM KIáº¾M ÄA NGUá»’N (Hybrid Search)
def search_in_index(idx, docs, query_vec, threshold=0.35, top_k=3):
    if not idx or not docs: return []
    scores, indices = idx.search(query_vec, top_k)
    results = []
    for i, score in enumerate(scores[0]):
        if score >= threshold:
            results.append(docs[indices[0][i]])
    return results

def vector_search(query):
    try:
        # MÃ£ hÃ³a cÃ¢u há»i (DÃ¹ng OpenAI)
        response = openai_client.embeddings.create(
            input=query,
            model="text-embedding-3-small"
        )
        q_vec = np.array([response.data[0].embedding]).astype('float32')
        faiss.normalize_L2(q_vec) 
        
        # 1. TÃ¬m trong XÃƒ GIAO (Æ¯u tiÃªn cao, ngÆ°á»¡ng cháº·t cháº½ hÆ¡n Ä‘á»ƒ trÃ¡nh nháº§m)
        # NgÆ°á»¡ng 0.45 Ä‘á»ƒ Ä‘áº£m báº£o cÃ¢u xÃ£ giao pháº£i khÃ¡ khá»›p má»›i láº¥y
        social_results = search_in_index(index_social, docs_social, q_vec, threshold=0.45, top_k=2)
        
        # 2. TÃ¬m trong LUáº¬T (NgÆ°á»¡ng 0.35)
        law_results = search_in_index(index_luat, docs_luat, q_vec, threshold=0.35, top_k=5)
        
        # Gá»™p káº¿t quáº£
        final_results = social_results + law_results
        
        if final_results:
            return "\n---\n".join(final_results)
        else:
            return ""
            
    except Exception as e:
        print(f"âŒ Lá»—i tÃ¬m kiáº¿m: {e}")
        return ""

# 6. API Xá»­ lÃ½ Chat
class ChatRequest(BaseModel):
    prompt: str

@app.post("/api/process")
async def process_data(request: ChatRequest):
    user_input = request.prompt
    
    # BÆ¯á»šC A: TÃŒM KIáº¾M Dá»® LIá»†U
    context = vector_search(user_input)
    
    # BÆ¯á»šC B: CHUáº¨N Bá»Š PROMPT
    if context:
        source_instruction = f"Dá»® LIá»†U TÃŒM ÄÆ¯á»¢C Tá»ª KHO KIáº¾N THá»¨C:\n{context}"
        footer_warning = ""
    else:
        source_instruction = "KhÃ´ng tÃ¬m tháº¥y trong dá»¯ liá»‡u náº¡p sáºµn. HÃ£y dÃ¹ng kiáº¿n thá»©c chung cá»§a báº¡n vá» Luáº­t Giao thÃ´ng (NÄ 100/2019, 123/2021) Ä‘á»ƒ tráº£ lá»i."
        footer_warning = "\n\nâš ï¸ _(ThÃ´ng tin tham kháº£o tá»« kiáº¿n thá»©c tá»•ng há»£p)_"

    system_prompt = f"""
    Báº¡n lÃ  Trá»£ lÃ½ AI Giao thÃ´ng Viá»‡t Nam thÃ´ng minh, hÃ i hÆ°á»›c vÃ  am hiá»ƒu luáº­t.

    {source_instruction}

    HÆ¯á»šNG DáºªN Xá»¬ LÃ QUAN TRá»ŒNG:
    1. **PHÃ‚N LOáº I Dá»® LIá»†U:**
       - Náº¿u dá»¯ liá»‡u tÃ¬m Ä‘Æ°á»£c cÃ³ nhÃ£n `[XÃƒ GIAO]`: HÃ£y tráº£ lá»i theo giá»ng Ä‘iá»‡u thÃ¢n thiá»‡n, hÃ i hÆ°á»›c hoáº·c "cÃ  khá»‹a" nháº¹ nhÃ ng nhÆ° trong dá»¯ liá»‡u máº«u.
       - Náº¿u dá»¯ liá»‡u lÃ  LUáº¬T: HÃ£y tráº£ lá»i nghiÃªm tÃºc, chÃ­nh xÃ¡c, ngáº¯n gá»n.
       - Náº¿u cÃ³ cáº£ hai: HÃ£y chÃ o há»i xÃ£ giao trÆ°á»›c, sau Ä‘Ã³ tráº£ lá»i luáº­t.

    2. **QUY Táº®C TRÃŒNH BÃ€Y (MARKDOWN):**
       - **TUYá»†T Äá»I KHÃ”NG** dÃ¹ng dáº¥u sao (*) á»Ÿ Ä‘áº§u dÃ²ng danh sÃ¡ch.
       - DÃ¹ng dáº¥u gáº¡ch ngang (-) cho danh sÃ¡ch.
       - DÃ¹ng **In Ä‘áº­m** (bá»c trong 2 dáº¥u sao) cho: Sá»‘ tiá»n pháº¡t, TÃªn lá»—i, Tá»« khÃ³a.
       - Giá»¯a cÃ¡c Ã½ chÃ­nh pháº£i cÃ³ **má»™t dÃ²ng trá»‘ng**.
       - LuÃ´n thÃªm Emoji (ğŸš—, ğŸ›µ, ğŸ›‘, ğŸ’°, ğŸ‘®, ğŸ˜‚, ğŸ‘‹) Ä‘á»ƒ sinh Ä‘á»™ng.

    3. **Ná»˜I DUNG:**
       - Náº¿u lÃ  cÃ¢u há»i luáº­t: **PHáº¢I** ghi rÃµ má»©c pháº¡t cá»¥ thá»ƒ (VD: **2.000.000Ä‘**).
       - Náº¿u lÃ  cÃ¢u há»i xÃ£ giao/trÃªu Ä‘Ã¹a: HÃ£y Ä‘á»‘i Ä‘Ã¡p láº¡i thÃ´ng minh.
    """

    final_prompt = f"NgÆ°á»i dÃ¹ng nÃ³i: {user_input} {footer_warning}"

    # BÆ¯á»šC C: Gá»ŒI GEMINI (Sá»­a láº¡i model chuáº©n 1.5-flash)
    global key_index
    for i in range(len(GOOGLE_KEYS)):
        try:
            current_key = get_current_google_key()
            genai.configure(api_key=current_key)
            
            # LÆ°u Ã½: Google chÆ°a cÃ³ báº£n 2.5-flash public, dÃ¹ng 1.5-flash lÃ  á»•n Ä‘á»‹nh nháº¥t
            model = genai.GenerativeModel('gemini-1.5-flash')
            
            response = model.generate_content(f"{system_prompt}\n\n{final_prompt}")
            return {"answer": response.text}
            
        except Exception as e:
            print(f"âš ï¸ Lá»—i Gemini (Key {i}): {e}")
            key_index += 1
            time.sleep(0.5)
            
    return {"answer": "ğŸ˜” Há»‡ thá»‘ng Ä‘ang quÃ¡ táº£i. Báº¡n vui lÃ²ng thá»­ láº¡i sau giÃ¢y lÃ¡t nhÃ©!"}
