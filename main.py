from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
import faiss
import pickle
import numpy as np
import os
from openai import OpenAI
import time

app = FastAPI()

# 1. C·∫•u h√¨nh CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], 
    allow_methods=["*"],
    allow_headers=["*"],
)

# 2. C·∫•u h√¨nh OpenAI Client
# L·∫•y Key t·ª´ bi·∫øn m√¥i tr∆∞·ªùng tr√™n Render
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=OPENAI_API_KEY)

# 3. API Health Check (S·ª≠a l·ªói 404 Ping)
@app.get("/")
def read_root():
    return {"status": "OpenAI Server is running"}

# 4. Load Database (B·∫Øt bu·ªôc ph·∫£i l√† DB t·∫°o b·∫±ng OpenAI)
print("üì• ƒêang t·∫£i c∆° s·ªü d·ªØ li·ªáu lu·∫≠t...")
index = None
documents = None

try:
    if os.path.exists("luat_vn.index") and os.path.exists("luat_vn.pkl"):
        index = faiss.read_index("luat_vn.index")
        with open("luat_vn.pkl", "rb") as f:
            documents = pickle.load(f)
        print(f"‚úÖ ƒê√£ t·∫£i xong! T·ªïng c·ªông {len(documents)} ƒëo·∫°n lu·∫≠t.")
    else:
        print("‚ö†Ô∏è L·ªói: Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu. H√£y ƒë·∫£m b·∫£o b·∫°n ƒë√£ ch·∫°y build_db_openai.py!")
except Exception as e:
    print(f"‚ùå L·ªói khi t·∫£i DB: {e}")

# 5. H√†m t√¨m ki·∫øm Vector (D√πng OpenAI Embeddings)
def vector_search(query):
    if not index or not documents:
        return ""

    try:
        # T·∫°o vector t·ª´ c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng
        response = client.embeddings.create(
            input=query,
            model="text-embedding-3-small"
        )
        q_vec = np.array([response.data[0].embedding]).astype('float32')
        faiss.normalize_L2(q_vec) 
        
        # T√¨m 5 ƒëo·∫°n lu·∫≠t kh·ªõp nh·∫•t
        scores, indices = index.search(q_vec, 5)
        
        relevant_docs = []
        for i, score in enumerate(scores[0]):
            if score >= 0.35: # Ng∆∞·ª°ng l·ªçc ƒë·ªô ch√≠nh x√°c
                relevant_docs.append(documents[indices[0][i]])
        
        if relevant_docs:
            return "\n---\n".join(relevant_docs)
        else:
            return ""
            
    except Exception as e:
        print(f"L·ªói t√¨m ki·∫øm: {e}")
        return ""

# 6. API X·ª≠ l√Ω Chat
class ChatRequest(BaseModel):
    prompt: str

@app.post("/api/process")
async def process_data(request: ChatRequest):
    user_input = request.prompt
    
    # B∆∞·ªõc A: T√¨m ki·∫øm d·ªØ li·ªáu lu·∫≠t
    context = vector_search(user_input)
    
    # B∆∞·ªõc B: X√¢y d·ª±ng Prompt
    if context:
        system_content = f"""
        B·∫°n l√† Tr·ª£ l√Ω Ph√°p lu·∫≠t Giao th√¥ng Vi·ªát Nam (Ngh·ªã ƒë·ªãnh 168/2024).
        D∆∞·ªõi ƒë√¢y l√† th√¥ng tin tr√≠ch xu·∫•t t·ª´ vƒÉn b·∫£n lu·∫≠t:
        ---------------------
        {context}
        ---------------------
        Y√äU C·∫¶U:
        1. CH·ªà s·ª≠ d·ª•ng th√¥ng tin tr√™n ƒë·ªÉ tr·∫£ l·ªùi.
        2. Ghi r√µ m·ª©c ph·∫°t ti·ªÅn c·ª• th·ªÉ (n·∫øu c√≥).
        3. Tr·∫£ l·ªùi ng·∫Øn g·ªçn, s√∫c t√≠ch.
        """
    else:
        system_content = """
        B·∫°n l√† Tr·ª£ l√Ω Giao th√¥ng. Hi·ªán t·∫°i trong c∆° s·ªü d·ªØ li·ªáu kh√¥ng c√≥ th√¥ng tin v·ªÅ c√¢u h·ªèi n√†y.
        H√£y kh√©o l√©o xin l·ªói v√† g·ª£i √Ω ng∆∞·ªùi d√πng h·ªèi v·ªÅ c√°c l·ªói vi ph·∫°m ph·ªï bi·∫øn.
        """

    # B∆∞·ªõc C: G·ªçi GPT-4o-mini ƒë·ªÉ tr·∫£ l·ªùi
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini", # Model b·∫°n y√™u c·∫ßu
            messages=[
                {"role": "system", "content": system_content},
                {"role": "user", "content": user_input}
            ],
            temperature=0.3, # Gi·ªØ cho c√¢u tr·∫£ l·ªùi ·ªïn ƒë·ªãnh, √≠t b·ªãa ƒë·∫∑t
            max_tokens=500
        )
        
        return {"answer": response.choices[0].message.content}
        
    except Exception as e:
        print(f"L·ªói OpenAI: {e}")
        return {"answer": "H·ªá th·ªëng ƒëang b·∫≠n, vui l√≤ng th·ª≠ l·∫°i sau."}
