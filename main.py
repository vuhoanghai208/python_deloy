from fastapi import FastAPI, HTTPException, Request
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware

import faiss
import pickle
import numpy as np
import os
import time
import asyncio

from google import genai
from ddgs import DDGS
from openai import AsyncOpenAI

# ================= 1. APP CONFIG =================
app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# ================= 2. API KEYS =================
GOOGLE_KEYS_STR = os.getenv("GOOGLE_API_KEYS", "")
GOOGLE_KEYS = [k.strip() for k in GOOGLE_KEYS_STR.split(",") if k.strip()]

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None

# ================= 3. RATE LIMIT =================
RATE_LIMIT = {}
LIMIT = 50
WINDOW = 60

def check_rate_limit(ip: str) -> bool:
    now = time.time()
    RATE_LIMIT.setdefault(ip, [])
    RATE_LIMIT[ip] = [t for t in RATE_LIMIT[ip] if now - t < WINDOW]

    if len(RATE_LIMIT[ip]) >= LIMIT:
        return False

    RATE_LIMIT[ip].append(now)
    return True

# ================= 4. LOAD FAISS =================
def load_faiss_db(index_file, pkl_file):
    if not (os.path.exists(index_file) and os.path.exists(pkl_file)):
        return None, None
    index = faiss.read_index(index_file)
    with open(pkl_file, "rb") as f:
        docs = pickle.load(f)
    return index, docs

index_luat, docs_luat = load_faiss_db("luat_vn.index", "luat_vn.pkl")
index_social, docs_social = load_faiss_db("xa_giao.index", "xa_giao.pkl")

# ================= 5. EMBEDDING =================
async def get_embedding_async(text: str):
    if not openai_client:
        return None
    resp = await openai_client.embeddings.create(
        model="text-embedding-3-small",
        input=text
    )
    vec = np.array([resp.data[0].embedding], dtype="float32")
    faiss.normalize_L2(vec)
    return vec

def search_index(index, docs, vector, top_k=3, threshold=0.0):
    if index is None or vector is None:
        return []
    scores, ids = index.search(vector, top_k)
    results = []
    for score, idx in zip(scores[0], ids[0]):
        if score >= threshold and 0 <= idx < len(docs):
            results.append(docs[idx])
    return results

# ================= 6. DUCKDUCKGO (SAFE) =================
def ddg_search_sync(query: str):
    with DDGS() as ddgs:
        return list(ddgs.text(query, max_results=2, region="vn-vn"))

async def ddg_search(query: str):
    return await asyncio.to_thread(ddg_search_sync, query)

# ================= 7. HYBRID SEARCH =================
async def hybrid_search(query: str) -> str:
    parts = []
    vec = await get_embedding_async(query)

    social = search_index(index_social, docs_social, vec, 2, 0.45)
    if social:
        parts.append("[X√É GIAO]\n" + "\n".join(social))

    law = search_index(index_luat, docs_luat, vec, 5, 0.35)
    if law:
        parts.append("[LU·∫¨T]\n" + "\n".join(law))
    else:
        try:
            web = await ddg_search(f"{query} lu·∫≠t giao th√¥ng Vi·ªát Nam 2025")
            if web:
                parts.append("[WEB]\n" + "\n".join(r["body"] for r in web if "body" in r))
        except Exception:
            pass

    return "\n\n---\n\n".join(parts)

# ================= 8. GEMINI CLIENT POOL =================
GEMINI_CLIENTS = {}

def get_gemini_client(api_key: str):
    if api_key not in GEMINI_CLIENTS:
        GEMINI_CLIENTS[api_key] = genai.Client(api_key=api_key)
    return GEMINI_CLIENTS[api_key]

async def call_gemini(api_key: str, prompt: str) -> str:
    client = get_gemini_client(api_key)
    resp = await client.models.generate_content(
        model="gemini-2.5-flash",
        contents=prompt
    )
    return resp.text

# ================= 9. GPT FALLBACK =================
async def call_gpt_fallback(prompt: str) -> str:
    if not openai_client:
        raise RuntimeError("Missing OpenAI API key")
    resp = await openai_client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "B·∫°n l√† chuy√™n gia Lu·∫≠t Giao th√¥ng Vi·ªát Nam."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.3
    )
    return resp.choices[0].message.content

# ================= 10. API =================
class ChatRequest(BaseModel):
    prompt: str

@app.post("/api/process")
async def process_data(req: Request, body: ChatRequest):
    ip = req.client.host
    if not check_rate_limit(ip):
        raise HTTPException(429, "Rate limit exceeded")

    user_input = body.prompt.strip()
    if not user_input:
        return {"answer": "B·∫°n ch∆∞a nh·∫≠p c√¢u h·ªèi."}

    context = await hybrid_search(user_input)

    system_instruction = """
    VAI TR√í: B·∫°n l√† Tr·ª£ l√Ω AI C·ªë v·∫•n Ph√°p lu·∫≠t Giao th√¥ng Vi·ªát Nam & B·∫°n ƒë∆∞·ªùng tin c·∫≠y.
    
    NHI·ªÜM V·ª§:
    1. N·∫øu l√† c√¢u h·ªèi X√É GIAO (Ch√†o h·ªèi, tr√™u ƒë√πa, h·ªèi t√™n...):
       - Tr·∫£ l·ªùi th√¢n thi·ªán, h√†i h∆∞·ªõc, ng·∫Øn g·ªçn.
       
    2. N·∫øu l√† c√¢u h·ªèi LU·∫¨T/KI·∫æN TH·ª®C:
       - D·ª±a tuy·ªát ƒë·ªëi v√†o [NG·ªÆ C·∫¢NH THAM KH·∫¢O] b√™n d∆∞·ªõi.
       - Tr√≠ch d·∫´n Ngh·ªã ƒë·ªãnh 100/2019 ho·∫∑c 123/2021 ho·∫∑c 168/2024.
       - N√™u r√µ: M·ª©c ph·∫°t ti·ªÅn (In ƒë·∫≠m) v√† H√¨nh ph·∫°t b·ªï sung (T∆∞·ªõc b·∫±ng, giam xe...).
       - Tr√¨nh b√†y d·∫°ng danh s√°ch (Bullet points) d·ªÖ ƒë·ªçc.
    
    3. NGUY√äN T·∫ÆC:
       - Kh√¥ng b·ªãa ƒë·∫∑t m·ª©c ph·∫°t.
       - Lu√¥n d√πng Emoji (üöó, üëÆ, üí∞) ƒë·ªÉ sinh ƒë·ªông.
    """

    final_prompt = f"""
[SYSTEM]
{system_instruction}

[CONTEXT]
{context or "Kh√¥ng c√≥ d·ªØ li·ªáu tham kh·∫£o."}

[QUESTION]
{user_input}

[ANSWER]
"""

    for idx, key in enumerate(GOOGLE_KEYS):
        try:
            answer = await call_gemini(key, final_prompt)
            return {
                "answer": answer,
                "model": "gemini",
                "key_used": idx
            }
        except Exception:
            continue

    answer = await call_gpt_fallback(final_prompt)
    return {
        "answer": answer,
        "model": "gpt-fallback"
    }

# ================= 11. HEALTH =================
@app.get("/")
def health():
    return {
        "status": "ok",
        "gemini_keys": len(GOOGLE_KEYS),
        "openai": bool(OPENAI_API_KEY),
        "db_law": index_luat is not None,
        "db_social": index_social is not None
    }
